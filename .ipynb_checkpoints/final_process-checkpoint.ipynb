{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "\n",
    "keys_dict = {\n",
    "        'consumer_key':        'Qi35siyIf3Arx4UD7sR5ELTFz',\n",
    "        'consumer_secret':     '989HQ87fXwciNjJN50eBEUBXWLrKi2OslwnnYPzAHcwwghURxH',\n",
    "        'access_token_key':    '1166189801315459072-OiZQVuvE1U9sPWUjbl8NE25eIqWhPk',\n",
    "        'access_token_secret': 'IOpQZF8RZnNKclQqOUKtmLVtYClg3waMdSFQZznKqIhRT'\n",
    "    }\n",
    "\n",
    "auth = tweepy.OAuthHandler(keys_dict['consumer_key'], keys_dict['consumer_secret'])\n",
    "auth.set_access_token(keys_dict['access_token_key'], keys_dict['access_token_secret'])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15846407"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get user id\n",
    "t = api.get_user('TheEllenShow')\n",
    "t._json['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of format_repliess:  1629\n",
      "len of format_tweets:  19\n"
     ]
    }
   ],
   "source": [
    "#India group\n",
    "\n",
    "# userid = '2220938808' \n",
    "# username = 'BJP4UP'\n",
    "\n",
    "# fn_re = \"hi/re_BJP4UP.json\"\n",
    "# replies = read(fn_re)\n",
    "# format_replies = process_replies_hi(replies, 'India', username, userid, 'hi')\n",
    "\n",
    "# fn_tw = \"hi/tw_BJP4UP.json\"\n",
    "# tweets = read(fn_tw)\n",
    "# format_tweets = process_tweets_hi(tweets, 'India', username, userid, 'hi')\n",
    "\n",
    "#### LOG\n",
    "# userid = '2220938808' \n",
    "# username = 'BJP4UP'\n",
    "# len of format_repliess:  1629\n",
    "# len of format_tweets:  19\n",
    "\n",
    "# userid = '798135834' \n",
    "# username = 'ptshrikant'\n",
    "# len of format_repliess:  5504\n",
    "# len of format_tweets:  48\n",
    "\n",
    "# userid = '130104041' \n",
    "# username = 'smritiirani'\n",
    "# len of format_repliess:  1605\n",
    "# len of format_tweets:  28\n",
    "\n",
    "# userid = '3437532637' \n",
    "# username = 'myogiadityanath'\n",
    "# len of format_repliess:  1418\n",
    "# len of format_tweets:  28\n",
    "\n",
    "# userid = '57948579' \n",
    "# username = 'yadavakhilesh'\n",
    "# len of format_repliess:  3579\n",
    "# len of format_tweets:  21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of format_repliess:  4569\n",
      "len of format_tweets:  46\n"
     ]
    }
   ],
   "source": [
    "#Brazil group\n",
    "\n",
    "# userid = '74756085' \n",
    "# username = 'BolsonaroSP'\n",
    "\n",
    "# fn_re = \"pt/re_BolsonaroSP.json\"\n",
    "# replies = read(fn_re)\n",
    "# format_replies = process_replies_pt(replies, 'Brazil', username, userid, 'pt')\n",
    "\n",
    "# fn_tw = \"pt/tw_BolsonaroSP.json\"\n",
    "# tweets = read(fn_tw)\n",
    "# format_tweets = process_tweets_pt(tweets, 'Brazil', username, userid, 'pt')\n",
    "\n",
    "#### LOG\n",
    "# userid = '74756085' \n",
    "# username = 'BolsonaroSP'\n",
    "# len of format_repliess:  4569\n",
    "# len of format_tweets:  46\n",
    "\n",
    "# userid = '68712576' \n",
    "# username = 'CarlosBolsonaro'\n",
    "# len of format_repliess:  5420\n",
    "# len of format_tweets:  32\n",
    "\n",
    "# userid = '40053694' \n",
    "# username = 'FlavioBolsonaro'\n",
    "# len of format_repliess:  5420\n",
    "# len of format_tweets:  32\n",
    "\n",
    "# userid = '1058819604741525510' \n",
    "# username = 'GeneralMourao'\n",
    "# len of format_repliess:  4265\n",
    "# len of format_tweets:  23\n",
    "\n",
    "# userid = '128372940' \n",
    "# username = 'jairbolsonaro'\n",
    "# len of format_repliess:  6678\n",
    "# len of format_tweets:  34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of format_repliess:  2524\n",
      "len of format_tweets:  19\n"
     ]
    }
   ],
   "source": [
    "# USA group\n",
    "\n",
    "# userid = '236699098' \n",
    "# username = 'KylieJenner'\n",
    "\n",
    "# fn_re = \"en/re_KylieJenner.json\"\n",
    "# replies = read(fn_re)\n",
    "# format_replies = process_replies_en(replies, 'USA', username, userid, 'en')\n",
    "\n",
    "# fn_tw = \"en/tw_KylieJenner.json\"\n",
    "# tweets = read(fn_tw)\n",
    "# format_tweets = process_tweets_en(tweets, 'USA', username, userid, 'en')\n",
    "\n",
    "#### LOG\n",
    "# userid = '15846407' \n",
    "# username = 'TheEllenShow'\n",
    "# len of format_repliess:  3534\n",
    "# len of format_tweets:  36\n",
    "\n",
    "# userid = '18236230' \n",
    "# username = 'JeffreeStar'\n",
    "# len of format_repliess:  3740\n",
    "# len of format_tweets:  20\n",
    "\n",
    "# userid = '25365536' \n",
    "# username = 'KimKardashian' \n",
    "# len of format_repliess:  3145\n",
    "# len of format_tweets:  43\n",
    "\n",
    "# userid = '236699098' \n",
    "# username = 'KylieJenner'\n",
    "# len of format_repliess:  2524\n",
    "# len of format_tweets:  19\n",
    "\n",
    "# userid = '25073877' \n",
    "# username = 'realDonaldTrump'\n",
    "# len of format_repliess:  3310\n",
    "# len of format_tweets:  23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_replies_pt(replies, country, username, userid, lang):\n",
    "    format_replies = []\n",
    "    \n",
    "    for reply in replies:\n",
    "        text = reply['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "        \n",
    "        date = reply['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'False',\n",
    "             'country':         country,\n",
    "             'replied_to_tweet_id': reply['in_reply_to_status_id_str'],\n",
    "             'replied_to_user_id':  userid,\n",
    "             'reply_text':          reply['text'],\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_pt':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'Null'\n",
    "            }\n",
    "        format_replies.append(t)\n",
    "        \n",
    "    with io.open('pt_final/re_%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_replies, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_repliess: \", len(format_replies))\n",
    "        \n",
    "    return format_replies\n",
    "\n",
    "def process_tweets_pt(tweets, country, username, userid, lang):\n",
    "    format_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        text = tweet['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "            \n",
    "        date = tweet['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'True',\n",
    "             'country':         country,\n",
    "             'replied_to_tweet_id': 'Null',\n",
    "             'replied_to_user_id':  'Null',\n",
    "             'reply_text':          'Null',\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_pt':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'Null'\n",
    "            }\n",
    "        format_tweets.append(t)\n",
    "        \n",
    "    with io.open('pt_final/%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_tweets, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_tweets: \", len(format_tweets))\n",
    "    return format_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_replies_en(replies, country, username, userid, lang):\n",
    "    format_replies = []\n",
    "    \n",
    "    for reply in replies:\n",
    "        text = reply['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "        \n",
    "        date = reply['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'False',\n",
    "             'country':         country,\n",
    "             'replied_to_tweet_id': reply['in_reply_to_status_id_str'],\n",
    "             'replied_to_user_id':  userid,\n",
    "             'reply_text':          reply['text'],\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_en':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'Null'\n",
    "            }\n",
    "        format_replies.append(t)\n",
    "        \n",
    "    with io.open('en_final/re_%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_replies, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_repliess: \", len(format_replies))\n",
    "        \n",
    "    return format_replies\n",
    "\n",
    "def process_tweets_en(tweets, country, username, userid, lang):\n",
    "    format_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        text = tweet['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "            \n",
    "        date = tweet['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'True',\n",
    "             'country':         country,\n",
    "             'replied_to_tweet_id': 'Null',\n",
    "             'replied_to_user_id':  'Null',\n",
    "             'reply_text':          'Null',\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_en':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'Null'\n",
    "            }\n",
    "        format_tweets.append(t)\n",
    "        \n",
    "    with io.open('en_final/%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_tweets, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_tweets: \", len(format_tweets))\n",
    "    return format_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_replies_hi(replies, country, username, userid, lang):\n",
    "    format_replies = []\n",
    "    \n",
    "    for reply in replies:\n",
    "        text = reply['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "        \n",
    "        date = reply['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'False',\n",
    "             'country':         country,\n",
    "             'replied_to_tweet_id': reply['in_reply_to_status_id_str'],\n",
    "             'replied_to_user_id':  userid,\n",
    "             'reply_text':          reply['text'],\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_hi':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'Null'\n",
    "            }\n",
    "        format_replies.append(t)\n",
    "        \n",
    "    with io.open('hi_final/re_%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_replies, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_repliess: \", len(format_replies))\n",
    "        \n",
    "    return format_replies\n",
    "\n",
    "def process_tweets_hi(tweets, country, username, userid, lang):\n",
    "    format_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        text = tweet['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "            \n",
    "        date = tweet['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'True',\n",
    "             'country':         country,\n",
    "             'replied_to_tweet_id': 'Null',\n",
    "             'replied_to_user_id':  'Null',\n",
    "             'reply_text':          'Null',\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_hi':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'Null'\n",
    "            }\n",
    "        format_tweets.append(t)\n",
    "        \n",
    "    with io.open('hi_final/%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_tweets, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_tweets: \", len(format_tweets))\n",
    "    return format_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_replies_hi_old(replies, userid, username):\n",
    "    format_replies = []\n",
    "    \n",
    "    for reply in replies:\n",
    "        t = {\n",
    "            'replied_to_tweet_id': reply['in_reply_to_status_id_str'],\n",
    "            'replied_to_user_id':  userid,\n",
    "            'reply_text':          reply['text']\n",
    "            }\n",
    "        format_replies.append(t)\n",
    "        \n",
    "    with io.open('hi_final/re_%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_replies, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_repliess: \", len(format_replies))\n",
    "        \n",
    "    return format_replies\n",
    "\n",
    "def process_tweets_hi_old(tweets, country, username, userid, lang):\n",
    "    format_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        text = tweet['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "            \n",
    "        date = tweet['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'True',\n",
    "             'country':         country,\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_hi':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'None'\n",
    "            }\n",
    "        format_tweets.append(t)\n",
    "        \n",
    "    with io.open('hi_final/%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_tweets, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_tweets: \", len(format_tweets))\n",
    "    return format_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_replies_pt_old(replies, userid, username):\n",
    "    format_replies = []\n",
    "    \n",
    "    for reply in replies:\n",
    "        t = {\n",
    "            'replied_to_tweet_id': reply['in_reply_to_status_id_str'],\n",
    "            'replied_to_user_id':  userid,\n",
    "            'reply_text':          reply['text']\n",
    "            }\n",
    "        format_replies.append(t)\n",
    "        \n",
    "    with io.open('pt_final/re_%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_replies, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_repliess: \", len(format_replies))\n",
    "        \n",
    "    return format_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets_pt_old(tweets, country, username, userid, lang):\n",
    "    format_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        text = tweet['text']\n",
    "        \n",
    "        if text.startswith('RT'):\n",
    "            continue\n",
    "            \n",
    "        date = tweet['created_at']\n",
    "            \n",
    "        t = {\n",
    "             'poi_name':        username,\n",
    "             'poi_id':          userid,\n",
    "             'verified':        'True',\n",
    "             'country':         country,\n",
    "             'tweet_lang':      lang,\n",
    "             'tweet_text':      text,\n",
    "             'text_pt':         process_text(text),\n",
    "             'hashtags':        find_hashtags(text), \n",
    "             'mentions':        find_mentions(text), \n",
    "             'tweet_urls':      find_urls(text),\n",
    "             'tweet_emoticons': find_emoticons(text),\n",
    "             'tweet_date':      format_date(date),\n",
    "             'tweet_loc':       'None'\n",
    "            }\n",
    "        format_tweets.append(t)\n",
    "        \n",
    "    with io.open('pt_final/%s.json' % username, 'a', encoding='utf8') as outfile:\n",
    "        re = json.dumps(format_tweets, indent=4, sort_keys=False, separators=(',', ': '), ensure_ascii=True)\n",
    "        outfile.write(re)\n",
    "        \n",
    "    print(\"len of format_tweets: \", len(format_tweets))\n",
    "    return format_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    hashtags = find_hashtags(text)\n",
    "    mentions = find_mentions(text)\n",
    "    emoticons = find_emoticons(text)\n",
    "    urls = find_urls(text)\n",
    "\n",
    "    for s in text.split(\" \"):\n",
    "        if s in hashtags or s in mentions or s in emoticons or s in urls:\n",
    "            text = text.replace(s, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@joey', '@toby']\n",
      "['#midautum', '#festival', '#moon']\n",
      "['http://www.happy.cn']\n",
      "[':)']\n"
     ]
    }
   ],
   "source": [
    "text = \"hello how are you @joey #midautum @toby #festival #moon http://www.happy.cn :) ;->\"\n",
    "print(find_mentions(text))\n",
    "print(find_hashtags(text))\n",
    "print(find_urls(text))\n",
    "print(find_emoticons(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date):\n",
    "    day = date.split(\" \")[2]\n",
    "    if len(day) == 1:\n",
    "        day = '0' + day\n",
    "        \n",
    "    hour = date.split(\" \")[3].split(\":\")[0]\n",
    "    if len(hour) == 1:\n",
    "        hour = '0' + hour\n",
    "        \n",
    "    f_date = '2019-09-' + day + 'T' + hour + ':00:00Z'\n",
    "#     print(f_date)\n",
    "    return f_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mentions(text):\n",
    "    mentions = []\n",
    "    ss = text.split(' ')\n",
    "    for s in ss:\n",
    "        if s.find('@') != -1:\n",
    "            mentions.append(s)\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(text):\n",
    "    hashtags = []\n",
    "    ss = text.split(' ')\n",
    "    for s in ss:\n",
    "        if s.find('#') != -1:\n",
    "            hashtags.append(s)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons = [':‑)',':)',':-]',':]',':-3', ':3', ':->',':>','8-)','8)',':-}',':}',':o)',':c)',':^)','=]','=)', #happy\n",
    "       ':D',':‑D','8‑D','8D','x‑D','xD','X‑D','XD','=D','=3','B^D',':-))', #laugh\n",
    "       ':‑(',':(',':‑c',':c',':‑<',':<',':‑[',':[',':-||','>:[',':{',':@','>:(',  #sad\n",
    "       ':‑P',':P','X‑P','XP','x‑p','xp',':‑p',':p',':‑Þ',':‑b',':b','d:','=p','>:P',  #playful\n",
    "       '>:‑)','}:)','>;)','>:3','>;3']  #evil\n",
    "\n",
    "def find_emoticons(text):\n",
    "    emos = []\n",
    "    for emo in emoticons:\n",
    "        if text.find(emo) != -1:\n",
    "            emos.append(emo)\n",
    "    return emos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_urls(text):\n",
    "    urls = []\n",
    "    ss = text.split(' ')\n",
    "    for s in ss:\n",
    "        if s.find('http') != -1:\n",
    "            urls.append(s)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(fn):\n",
    "    with open(fn) as f_read:\n",
    "        data = json.load(f_read)\n",
    "#         print(\"len of data\", len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
